{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Adding TPU Support"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\nAUTO = tf.data.experimental.AUTOTUNE\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset Utility Functions"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom PIL import Image, ImageSequence\n\nDATA_PATH = '/kaggle/input/medical-image-processing-2d-segmentation/'\nOUT_PATH = '/kaggle/working/'\n\ndef load_from_multi_page_tiff(path_to_image):\n    image_np_array_list = []\n    image_with_multi_page = Image.open(path_to_image)\n    for idx, page_image in enumerate(ImageSequence.Iterator(image_with_multi_page)):\n        image_np_array_list.append(np.array(page_image))\n    return np.stack(image_np_array_list)\n\ndef load_from_single_page_tiff(path_to_image):\n    return np.array(Image.open(path_to_image))\n\ndef get_image_shape(np_array):\n    if isinstance(np_array, (np.ndarray, np.generic)):\n        print(\"Loaded data shape: {}\".format(np_array.shape))\n    else:\n        print('Input type error!')\n\ndef seek_file_in_folder(folder_path):\n    return [os.path.join(folder_path, f) for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n\ndef parsing_cell_tracking_data(ground_truth_path):\n    x_image_array, y_image_array = [], []\n    for folder in ground_truth_path:\n        image_name_list = seek_file_in_folder(DATA_PATH + folder + '/SEG/')\n        seg_image_dict = dict()\n        for image_name in image_name_list:\n            name = image_name[-7:]\n            if '.txt' in name : continue\n            seg_image_dict[name] = load_from_single_page_tiff(image_name)\n        image_name_list_1 = seek_file_in_folder(DATA_PATH + folder[:-3])\n        x_image, y_image = [], []\n        for img_name, img_array in seg_image_dict.items():\n            matching = [s for s in image_name_list_1 if img_name in s]\n            x = load_from_single_page_tiff(matching[0])\n            x = cv2.resize(x, dsize = (512, 512))\n            y = cv2.resize(img_array, dsize = (512, 512))\n            x_image.append(x)\n            y_image.append(y)\n        x_image_array += x_image\n        y_image_array += y_image\n    return np.stack(x_image_array), np.stack(y_image_array)\n\ndef overlap_tile_processing(img_array, expend_px_width, expend_px_height):\n    def flip_horizontally(np_array):\n        return cv2.flip(np_array, 1)\n\n    def flip_vertically(np_array):\n        return cv2.flip(np_array, 0)\n\n    original_height = img_array.shape[0]\n    original_width = img_array.shape[1]\n\n    # Expand width first\n    # left:\n    left_result = flip_horizontally(img_array[0:0 + original_height, 0:0 + expend_px_width])\n    # right:\n    right_result = flip_horizontally(\n        img_array[0:0 + original_height, original_width - expend_px_width: original_width])\n\n    result_img = cv2.hconcat([left_result, img_array])\n    result_img = cv2.hconcat([result_img, right_result])\n\n    result_img_height = result_img.shape[0]\n    result_img_width = result_img.shape[1]\n\n    # Expand height\n    top_result = flip_vertically(result_img[0:0 + expend_px_height, 0:0 + result_img_width])\n    bottom_result = flip_vertically(\n        result_img[result_img_height - expend_px_height: result_img_height, 0:0 + result_img_width])\n\n    result_img = cv2.vconcat([top_result, result_img])\n    result_img = cv2.vconcat([result_img, bottom_result])\n\n    return result_img\n\ndef convert_to_datagen_format(py_list):\n    nparray = np.array(py_list)\n    return nparray.reshape(nparray.shape + (1,))\n\ndef data_generator(x, batch_size=10, epoch=50, seed=2003):\n    data_gen_args = dict(rotation_range=90,\n                     width_shift_range=0.05,\n                     height_shift_range=0.05,\n                     shear_range=30,\n                     zoom_range=0.05,\n                     horizontal_flip=True,\n                     vertical_flip=True,\n                     fill_mode='reflect')\n    datagen = ImageDataGenerator(**data_gen_args)\n    datagen_generator = datagen.flow(x, batch_size=batch_size, seed=seed)\n    tmp_x, i = list(), 0\n    for batch_x in datagen_generator:\n        tmp_x += list(batch_x)\n        i += 1\n        if i >= epoch: \n            return np.array(tmp_x)\n\ndef split_image2_4patch(imgs):\n    ret = list()\n    for x in imgs:\n        ret.append(x[0:572, 0:572, :].copy())\n        ret.append(x[0:572, 124:696, :].copy())\n        ret.append(x[124:696, 0:572, :].copy())\n        ret.append(x[124:696, 124:696, :].copy())\n    return np.array(ret)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset Loading Functions\nAll images have been resized to 512x512"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_ISBI_2012_dataset():\n    \"\"\"\n    Loading from ISBI dataset and convert to two image array (raw_data & ground_truth)\n    :return: np_array, np_array\n    \"\"\"\n    x_image_array = load_from_multi_page_tiff(path_to_image=DATA_PATH + 'ISBI2012/train-volume.tif')\n    y_image_array = load_from_multi_page_tiff(path_to_image=DATA_PATH + 'ISBI2012/train-labels.tif')\n    get_image_shape(x_image_array)\n    x = np.array(x_image_array, dtype = np.float32) / 255\n    y = np.array(y_image_array, dtype = np.float32) / 255\n    return x, y\n\ndef get_DIC_C2DH_HeLa():\n    \"\"\"\n    get DIC C2DH HeLa dataset where had ground truth data only\n    :return: x_np_array, y_np_array\n    \"\"\"\n    folder_path_list = ['PhC-C2DH-U373/01_GT', 'PhC-C2DH-U373/02_GT']\n    x, y = parsing_cell_tracking_data(folder_path_list)\n    get_image_shape(x)\n    y[y > 0] = 255\n    x = np.array(x, dtype = np.float32) / 255\n    y = np.array(y, dtype = np.float32) / 255\n    return x, y\n\ndef get_PhC_C2DH_U373():\n    \"\"\"\n    get PhC C2DH U373 dataset where had ground truth data only\n    :return: x_np_array, y_np_array\n    \"\"\"\n    folder_path_list = ['DIC-C2DH-HeLa/01_GT', 'DIC-C2DH-HeLa/02_GT']\n    x, y = parsing_cell_tracking_data(folder_path_list)\n    get_image_shape(x)\n    y[y > 0] = 255\n    x = np.array(x, dtype = np.float32) / 255\n    y = np.array(y, dtype = np.float32) / 255\n    return x, y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Weight map generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"# weight maps for binary masks\nimport scipy.ndimage as ndi\ndef weight_map(img, w0=10, sigma=5):\n    \"\"\"\n    Create a UNet weight map from a boolean `mask` where `True`\n    marks the interior pixels of an instance.\n    \"\"\"\n    mask = np.array(img, dtype=np.int32)\n    # if the mask only has one contiguous class,\n    # then there isn't much to do.\n    if len(np.unique(mask)) == 1:\n        return np.ones(mask.shape, dtype=np.float32) * 0.5\n\n    # calculate the class-balanced weight map w_c\n    w_c = np.zeros(mask.shape, dtype=np.float32)\n    w_1 = 1 - float(np.count_nonzero(mask)) / w_c.size\n    w_0 = 1 - w_1\n    w_c[mask > 0.5] = w_1\n    w_c[mask < 0.5] = w_0\n\n    # calculate the distance-weighted emphases w_e\n    segs, _ = ndi.label(mask)\n    if segs.max() == 1:\n        # if there is only 1 instance plus background,\n        # then there are no separations\n        return w_c\n    ilabels = range(1, segs.max()+1)\n    distmaps = np.stack([ndi.distance_transform_edt(segs != l) for l in ilabels])\n    distmaps = np.sort(distmaps, axis=0)[:2]\n    w_e = w0 * np.exp((-1 * (distmaps[0] + distmaps[1]) ** 2) / (2 * (sigma ** 2)))\n    w_e[mask] = 0.\n    return w_c + w_e\n\ndef get_weight_maps(data):\n    weight_maps = []\n    m = data.shape[0]\n    print('Generating weight maps...')\n    for i, img in enumerate(data):\n        cur = weight_map(img)\n        weight_maps.append(cur)\n        if (i + 1) % 15 == 0 : \n            print(i + 1)\n        elif (i + 1) == m:\n            print(i + 1)\n        else : \n            print(i + 1, end=' ')\n    return weight_maps","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualise function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def visualize_pred(x, y_true, y_pred, title1=\"Original\", title2=\"True\", title3=\"Predicted\", cmap='gray'):\n    fig = plt.figure()\n    fig.set_figheight(15)\n    fig.set_figwidth(15)\n    \n    ax = plt.subplot(\"131\")\n    ax.set_title(title1)\n    ax.imshow(np.squeeze(x), cmap=cmap)\n\n    ax = plt.subplot(\"132\")\n    ax.set_title(title2)\n    ax.imshow(np.squeeze(y_true), cmap=cmap)\n    \n    ax = plt.subplot(\"133\")\n    ax.set_title(title3)\n    ax.imshow(np.squeeze(y_pred), cmap=cmap)\n    \n    ctr = 1\n    file = 'plots_' + str(ctr) + '.png'\n    while os.path.isfile(file):\n        ctr += 1\n        file = 'plots_' + str(ctr) + '.png'\n    plt.savefig(file, bbox_inches='tight')\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Loading"},{"metadata":{"trusted":true},"cell_type":"code","source":"# DATA for everything\nfrom glob import glob\ncur = 'HeLa'\n\ndef name(s):\n    return OUT_PATH + str(s) + '_' + cur + '.npy'\n\ndef get_data():\n    if cur == 'ISBI' : return get_ISBI_2012_dataset()\n    if cur == 'HeLa' : return get_DIC_C2DH_HeLa()\n    if cur == 'U373' : return get_PhC_C2DH_U373()\n    print('Wrong name specified')\n\nprint('Deleting old files...')\nfor file in glob('*.npy'):\n    os.remove(file)\n\nprint('Loading {} dataset...'.format(cur))\nX_0, Y_0 = get_data()\nW_0 = get_weight_maps(Y_0)\n\nX_1 = convert_to_datagen_format(X_0)\nY_1 = convert_to_datagen_format(Y_0)\nW_1 = convert_to_datagen_format(W_0)\n\nprint('Augmenting data...')\nX = data_generator(X_1, batch_size=10, epoch=100, seed=2003) \nY = data_generator(Y_1, batch_size=10, epoch=100, seed=2003) \nW = data_generator(W_1, batch_size=10, epoch=100, seed=2003) \nprint('Shape : {}'.format(X.shape))\n\n# print('Saving data...')\n# np.save(name('X'), X)\n# np.save(name('Y'), Y)\n# np.save(name('W'), W)\n# print(\"Saved successfully\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# only for uNet1\ndef uNet1_preprocess(x, y, w):\n    X_1, Y_1, W_1 = list(), list(), list()\n    for i in range(x.shape[0] // 4):\n        X_1.append(overlap_tile_processing(x[i, :, :, 0], 92, 92))\n        Y_1.append(overlap_tile_processing(y[i, :, :, 0], 92, 92))\n        W_1.append(overlap_tile_processing(w[i, :, :, 0], 92, 92))\n    \n    X_1 = convert_to_datagen_format(X_1)\n    Y_1 = convert_to_datagen_format(Y_1)\n    W_1 = convert_to_datagen_format(W_1)\n    \n    X_2 = split_image2_4patch(X_1)\n    Y_2 = split_image2_4patch(Y_1)\n    W_2 = split_image2_4patch(W_1)\n    \n    Y_2 = Y_2[:, 92:-92, 92:-92, :]\n    W_2 = W_2[:, 92:-92, 92:-92, :]\n    print('X shape : {}'.format(X_2.shape))\n    print('Y shape : {}'.format(Y_2.shape))\n    return X_2, Y_2, W_2\n\n# X, Y, W = uNet1_preprocess(X, Y, W)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = np.random.randint(0, X.shape[0], size = 3)\nfor index in ids:\n    xx, yy, ww = X[index], Y[index], W[index]\n    visualize_pred(xx, yy, ww, title1=\"Original\", title2=\"True\", title3=\"WeightMap\")\n#     visualize_pred(xx[92:-92, 92:-92, :], yy, ww, title1=\"Original\", title2=\"True\", title3=\"WeightMap\")    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val, W_train, W_val = train_test_split(X, Y, W, test_size=0.1)\nX_val, X_test, Y_val, Y_test, W_val, W_test = train_test_split(X_val, Y_val, W_val, test_size=0.5)\nprint('Train: X = {} Y = {}'.format(X_train.shape, Y_train.shape))\nprint('Val: X = {} Y = {}'.format(X_val.shape, Y_val.shape))\nprint('Test: X = {} Y = {}'.format(X_test.shape, Y_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# only for weighted_uNet\n# X_train = [X_train, W_train, Y_train]\n# X_val = [X_val, W_val, Y_val]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Architectures"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Cropping2D, Conv2D, Conv2DTranspose, MaxPooling2D, Softmax\nfrom tensorflow.keras.layers import Input, Add, Multiply, Lambda, Concatenate, Dropout\nimport tensorflow.keras.backend as K\n\n# loss will be binary_crossentropy\ndef uNet1():\n    concat_axis = 3\n    k_init = 'he_normal'\n    with strategy.scope():\n        inputs = Input((572, 572, 1), name='image_input')\n        conv1_1 = Conv2D(64, (3, 3), activation='relu', padding='valid', kernel_initializer=k_init)(inputs)\n        conv1_2 = Conv2D(64, (3, 3), activation='relu', padding='valid', kernel_initializer=k_init)(conv1_1)\n        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1_2)\n\n        conv2_1 = Conv2D(128, (3, 3), activation='relu', padding='valid', kernel_initializer=k_init)(pool1)\n        conv2_2 = Conv2D(128, (3, 3), activation='relu', padding='valid', kernel_initializer=k_init)(conv2_1)\n        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2_2)\n\n        conv3_1 = Conv2D(256, (3, 3), activation='relu', padding='valid', kernel_initializer=k_init)(pool2)\n        conv3_2 = Conv2D(256, (3, 3), activation='relu', padding='valid', kernel_initializer=k_init)(conv3_1)\n        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3_2)\n\n        conv4_1 = Conv2D(512, (3, 3), activation='relu', padding='valid', kernel_initializer=k_init)(pool3)\n        conv4_2 = Conv2D(512, (3, 3), activation='relu', padding='valid', kernel_initializer=k_init)(conv4_1)\n        pool4 = MaxPooling2D(pool_size=(2, 2))(conv4_2)\n\n        conv5_1 = Conv2D(1024, (3, 3), activation='relu', padding='valid', kernel_initializer=k_init)(pool4)\n        conv5_2 = Conv2D(1024, (3, 3), activation='relu', padding='valid', kernel_initializer=k_init)(conv5_1)\n\n        upsampling1 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='valid', kernel_initializer=k_init)(conv5_2)\n        crop_conv4_2 = Cropping2D(cropping=((4, 4), (4, 4)))(conv4_2)\n        up6 = Concatenate(axis=concat_axis)([upsampling1, crop_conv4_2])\n        conv6_1 = Conv2D(512, (3, 3), activation='relu', padding='valid', kernel_initializer=k_init)(up6)\n        conv6_2 = Conv2D(512, (3, 3), activation='relu', padding='valid', kernel_initializer=k_init)(conv6_1)\n\n        upsampling2 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='valid', kernel_initializer=k_init)(conv6_2)\n        crop_conv3_2 = Cropping2D(cropping=((16, 16), (16, 16)))(conv3_2)\n        up7 = Concatenate(axis=concat_axis)([upsampling2, crop_conv3_2])\n        conv7_1 = Conv2D(256, (3, 3), activation='relu', padding='valid', kernel_initializer=k_init)(up7)\n        conv7_2 = Conv2D(256, (3, 3), activation='relu', padding='valid', kernel_initializer=k_init)(conv7_1)\n\n        upsampling3 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='valid', kernel_initializer=k_init)(conv7_2)\n        crop_conv2_2 = Cropping2D(cropping=((40, 40), (40, 40)))(conv2_2)\n        up8 = Concatenate(axis=concat_axis)([upsampling3, crop_conv2_2])\n        conv8_1 = Conv2D(128, (3, 3), activation='relu', padding='valid', kernel_initializer=k_init)(up8)\n        conv8_2 = Conv2D(128, (3, 3), activation='relu', padding='valid', kernel_initializer=k_init)(conv8_1)\n\n        upsampling4 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='valid', kernel_initializer=k_init)(conv8_2)\n        crop_conv1_2 = Cropping2D(cropping=((88, 88), (88, 88)))(conv1_2)\n        up9 = Concatenate(axis=concat_axis)([upsampling4, crop_conv1_2])\n        conv9_1 = Conv2D(64, (3, 3), activation='relu', padding='valid', kernel_initializer=k_init)(up9)\n        conv9_2 = Conv2D(64, (3, 3), activation='relu', padding='valid', kernel_initializer=k_init)(conv9_1)\n\n        conv10 = Conv2D(1, (1, 1), activation='sigmoid', kernel_initializer='glorot_normal', name='seg_output')(conv9_2)\n\n        model = Model(inputs=[inputs], outputs=[conv10])\n        return model\n    \n# with jaccard_loss and dice_loss, model converges to the trivial all-zeros solution and output completely black image \n# also softmax doesnt work\n# loss will be binary_crossentropy\ndef DMCN():\n    concat_axis = 3\n    k_init = 'he_normal'\n    with strategy.scope():\n        inputs = Input((512, 512, 1), name='image_input')\n        conv1 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer=k_init)(inputs)\n        conv2 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer=k_init)(conv1)\n        \n        pool3 = MaxPooling2D(pool_size=(2, 2))(conv2)\n        conv4 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer=k_init)(pool3)\n        conv5 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer=k_init)(conv4)\n        \n        pool6 = MaxPooling2D(pool_size=(2, 2))(conv5)\n        conv7 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer=k_init)(pool6)\n        conv8 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer=k_init)(conv7)\n        conv9 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer=k_init)(conv8)\n        \n        pool10 = MaxPooling2D(pool_size=(2, 2))(conv9)\n        conv11 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer=k_init)(pool10)\n        conv12 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer=k_init)(conv11)\n        conv13 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer=k_init)(conv12)\n        \n        upsampling1 = Conv2DTranspose(2, (2, 2), strides=(2, 2), padding='valid', kernel_initializer=k_init)(conv5)\n        conv1_1 = Conv2D(2, (3, 3), activation='relu', padding='same', kernel_initializer=k_init)(upsampling1)\n        conv1_2 = Conv2D(2, (1, 1), activation='relu', padding='same', kernel_initializer=k_init)(conv1_1)\n        \n        upsampling2 = Conv2DTranspose(2, (4, 4), strides=(4, 4), padding='valid', kernel_initializer=k_init)(conv9)\n        conv2_1 = Conv2D(2, (3, 3), activation='relu', padding='same', kernel_initializer=k_init)(upsampling2)\n        conv2_2 = Conv2D(2, (1, 1), activation='relu', padding='same', kernel_initializer=k_init)(conv2_1)\n        \n        upsampling3 = Conv2DTranspose(2, (8, 8), strides=(8, 8), padding='valid', kernel_initializer=k_init)(conv13)\n        conv3_1 = Conv2D(2, (3, 3), activation='relu', padding='same', kernel_initializer=k_init)(upsampling3)\n        conv3_2 = Conv2D(2, (1, 1), activation='relu', padding='same', kernel_initializer=k_init)(conv3_1)\n        \n        fusion = Concatenate(axis=concat_axis)([conv1_2, conv2_2, conv3_2])\n        conv14 = Conv2D(1, (1, 1), activation='sigmoid', padding='same', kernel_initializer='glorot_normal', name='seg_output')(fusion)\n        \n        model = Model(inputs=[inputs], outputs=[conv14])\n        return model\n    \ndef weighted_binary_loss(X):\n    y_true, y_pred = X\n    loss = K.binary_crossentropy(y_true, y_pred)\n    return loss\n\n# loss will be identity_loss\ndef weighted_uNet():\n    concat_axis = 3\n    k_init = 'he_normal'\n    _epsilon = tf.convert_to_tensor(K.epsilon(), np.float32)\n    with strategy.scope():\n        inputs = Input((512, 512, 1), name='image_input')\n\n        conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer=k_init)(inputs)\n        conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer=k_init)(conv1)\n        conv1 = Dropout(0.1)(conv1)\n        mpool1 = MaxPooling2D(pool_size=(2,2))(conv1)\n\n        conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer=k_init)(mpool1)\n        conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer=k_init)(conv2)\n        conv2 = Dropout(0.2)(conv2)\n        mpool2 = MaxPooling2D(pool_size=(2,2))(conv2)\n\n        conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer=k_init)(mpool2)\n        conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer=k_init)(conv3)\n        conv3 = Dropout(0.3)(conv3)\n        mpool3 = MaxPooling2D(pool_size=(2,2))(conv3)\n\n        conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer=k_init)(mpool3)\n        conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer=k_init)(conv4)\n        conv4 = Dropout(0.4)(conv4)\n        mpool4 = MaxPooling2D(pool_size=(2,2))(conv4)\n\n        conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer=k_init)(mpool4)\n        conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer=k_init)(conv5)\n        conv5 = Dropout(0.5)(conv5)\n\n        up6 = Conv2DTranspose(512, 2, strides=2, kernel_initializer=k_init, padding='same')(conv5)\n        conv6 = Concatenate(axis=concat_axis)([up6, conv4])\n        conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer=k_init)(conv6)\n        conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer=k_init)(conv6)\n        conv6 = Dropout(0.4)(conv6)\n\n        up7 = Conv2DTranspose(256, 2, strides=2, kernel_initializer=k_init, padding='same')(conv6)\n        conv7 = Concatenate(axis=concat_axis)([up7, conv3])\n        conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer=k_init)(conv7)\n        conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer=k_init)(conv7)\n        conv7 = Dropout(0.3)(conv7)\n\n        up8 = Conv2DTranspose(128, 2, strides=2, kernel_initializer=k_init, padding='same')(conv7)\n        conv8 = Concatenate(axis=concat_axis)([up8, conv2])\n        conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer=k_init)(conv8)\n        conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer=k_init)(conv8)\n        conv8 = Dropout(0.2)(conv8)\n\n        up9 = Conv2DTranspose(64, 2, strides=2, kernel_initializer=k_init, padding='same')(conv8)\n        conv9 = Concatenate(axis=concat_axis)([up9, conv1])\n        conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer=k_init)(conv9)\n        conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer=k_init)(conv9)\n        conv9 = Dropout(0.1)(conv9)\n\n        c10 = Conv2D(1, 1, activation='sigmoid', kernel_initializer='glorot_normal', name='seg_output')(conv9)\n        weight_inputs = Input((512, 512, 1))\n        true_inputs = Input((512, 512, 1))\n        loss1 = Lambda(weighted_binary_loss)([true_inputs, c10])\n        loss1 = Multiply()([loss1, weight_inputs])\n        model = Model(inputs=[inputs, weight_inputs, true_inputs], outputs=[loss1])\n        return model\n    \n# loss will be bce_dice_loss\ndef uNet2():\n    n_ch_exps = [4, 5, 6, 7, 8, 9]   #the n-th deep channel's exponent i.e. 2**n 16,32,64,128,256\n    k_size = (3, 3)\n    k_init = 'he_normal'\n    decoder_n_chs = n_ch_exps[::-1][1:]\n    concat_axis = 3\n\n    with strategy.scope():\n        inp = Input((512,512,1), name='image_input')\n        encodeds = []\n\n        # encoder\n        enc = inp\n        for l_idx, n_ch in enumerate(n_ch_exps):\n            enc = Conv2D(filters=2**n_ch, kernel_size=k_size, activation='relu', padding='same', kernel_initializer=k_init)(enc)\n            enc = Dropout(0.1 * l_idx,)(enc)\n            enc = Conv2D(filters=2**n_ch, kernel_size=k_size, activation='relu', padding='same', kernel_initializer=k_init)(enc)\n            encodeds.append(enc)\n            #do not run max pooling on the last encoding/downsampling step\n            if n_ch == n_ch_exps[-1]: break \n            enc = MaxPooling2D(pool_size=(2,2))(enc)\n\n        # decoder\n        dec = enc\n        for l_idx, n_ch in enumerate(decoder_n_chs):\n            l_idx_rev = len(n_ch_exps) - l_idx - 2  #\n            dec = Conv2DTranspose(filters=2**n_ch, kernel_size=k_size, strides=(2,2), activation='relu', padding='same', kernel_initializer=k_init)(dec)\n            dec = Concatenate(axis=concat_axis)([dec, encodeds[l_idx_rev]])\n            dec = Conv2D(filters=2**n_ch, kernel_size=k_size, activation='relu', padding='same', kernel_initializer=k_init)(dec)\n            dec = Dropout(0.1*l_idx)(dec)\n            dec = Conv2D(filters=2**n_ch, kernel_size=k_size, activation='relu', padding='same', kernel_initializer=k_init)(dec)\n\n        outp = Conv2DTranspose(filters=1, kernel_size=k_size, activation='sigmoid', padding='same', kernel_initializer='glorot_normal', name='seg_output')(dec)\n\n        model = Model(inputs=[inp], outputs=[outp])\n        return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loss functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# LOSS functions\ndef iou(true, pred):\n    intersection = true * pred\n    notTrue = 1 - true\n    union = true + (notTrue * pred)\n    return (K.sum(intersection, axis=-1) + K.epsilon()) / (K.sum(union, axis=-1) + K.epsilon())\n\ndef dice_coef(y_true, y_pred, smooth=1.0):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef bce_dice_loss(y_true, y_pred):\n    return 0.5 * K.binary_crossentropy(y_true, y_pred) - dice_coef(y_true, y_pred)\n\ndef jaccard_distance_loss(y_true, y_pred, smooth=100):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n    return (1 - jac) * smooth\n\ndef iou_loss(y_true, y_pred):\n    return 1 - iou(y_true, y_pred)\n\n# for weighted_uNet only\ndef identity_loss(y_true, y_pred):\n    return y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"K.clear_session()\nmodel = DMCN()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nmodel_name = 'weighted_unet.h5'\n\n# early stopping should always be the last callback\nstopper = EarlyStopping(monitor='loss', patience=5)\ncheckpointer = ModelCheckpoint(filepath=model_name, monitor='val_loss', mode='min', save_best_only=True)\nmodel.compile(optimizer = Adam(lr=0.001), loss = identity_loss)\n\nlosses = list()\nval_losses = list()\n\nif os.path.isfile(model_name):\n    print('Loaded saved Model!')\n    model.load_weights(model_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":false,"collapsed":true},"cell_type":"code","source":"history = model.fit(\n    X_train, Y_train,\n    batch_size = 10 * strategy.num_replicas_in_sync,\n    epochs = 100,\n    validation_data = (X_val, Y_val),\n    callbacks = [checkpointer, stopper],\n    shuffle = True,\n    verbose = 1\n)\n\nlosses += list(history.history['loss'])\nval_losses += list(history.history['val_loss'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from glob import glob\ndef delete_pngs():\n    for file in glob('*.png'):\n        os.remove(file)      \ndelete_pngs()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nfig.set_figheight(8)\nfig.set_figwidth(12)\nplt.plot(losses, label='LOSS (training data)')\nplt.plot(val_losses, label='LOSS (validation data)')\nplt.title('Loss Trend')\nplt.ylabel('LOSS value')\nplt.xlabel('No. of epochs')\nplt.legend(loc=\"upper left\")\nplt.savefig('loss_trend.png', bbox_inches='tight')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictor = K.function([model.get_layer('image_input').input], [model.get_layer('seg_output').output])\nY_pred = predictor(X_test)[0]\nprint('Pred : {}'.format(Y_pred.shape))\nprint('True : {}'.format(Y_test.shape))\nprint('Original : {}'.format(X_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize results\ntotal = X_test.shape[0]\nids = np.random.randint(0, total, size = 5)\nfor i in ids:\n    visualize_pred(X_test[i], Y_test[i], Y_pred[i])\n#     visualize_pred(X_test[i][92:-92, 92:-92, :], Y_test[i], Y_pred[i])    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def avg_pred(img):\n#     assert(img.shape == (512, 512))\n#     img = overlap_tile_processing(img, 92, 92)\n#     img = img.reshape((1,) + img.shape + (1,))\n#     imgs = split_image2_4patch(img)\n#     y_pred = predictor(imgs)[0]\n#     ret = np.zeros((512, 512), dtype=np.float32)\n#     ret[:388, :388] += y_pred[0,:,:,0]\n#     ret[:388, -388:] += y_pred[1,:,:,0]\n#     ret[-388:, :388] += y_pred[2,:,:,0]\n#     ret[-388:, -388:] += y_pred[3,:,:,0]\n#     ret /= 2\n#     ret[124:-124, 124:-124] /= 2\n#     ret[:124, :124] *= 2\n#     ret[:124, -124:] *= 2\n#     ret[-124:, :124] *= 2\n#     ret[-124:, -124:] *= 2\n#     return ret\n    \n# def resize_pred(img):\n#     assert(img.shape == (512, 512))\n#     img = cv2.resize(img, dsize = (388, 388))\n#     img = overlap_tile_processing(img, 92, 92)\n#     img = img.reshape((1,) + img.shape + (1,))\n#     y_pred = predictor(img)[0]\n#     ret = cv2.resize(y_pred[0, :, :, 0], dsize = (512, 512))\n#     return ret\n\n# total = X_0.shape[0]\n# ids = np.random.randint(0, total, size = 1)\n# for i in ids:\n#     ref = X_0[i]\n#     out1 = avg_pred(ref)\n#     out2 = resize_pred(ref)\n#     out1 = convert_to_datagen_format(out1)\n#     out2 = convert_to_datagen_format(out2)\n#     cur = convert_to_datagen_format(Y_0[i])\n#     visualize_pred(cur, out1, out2, title1=\"True Label\", title2=\"Avg Label\", title3=\"Resized Label\", cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for submitting online to ISBI challenge\n# def save_tif(images):\n#     imlist = []\n#     for m in images:\n#         imlist.append(Image.fromarray(m))\n#     imlist[0].save(\"tested.tif\", save_all=True, append_images=imlist[1:])\n\n# def submission():\n#     x_image_array = load_from_multi_page_tiff(path_to_image=DATA_PATH + 'ISBI2012/test-volume.tif')\n#     x_image_array = convert_to_datagen_format(x_image_array)\n#     test_x = np.array(x_image_array, dtype = np.float32) / 255\n#     test_y = np.squeeze(predictor(test_x)[0])\n#     save_tif(test_y)\n\n# submission()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Metrics\ndef iou_batch(y_trues_in, y_preds_in):\n    y_true = (y_trues_in >= 0.5).squeeze()\n    y_pred = (y_preds_in >= 0.5).squeeze()\n    unions = np.sum(y_pred | y_true, (1, 2))\n    intersections = np.sum(y_pred * y_true, (1, 2))\n    ious = np.maximum(0.0, np.ceil(20 * intersections / np.where(unions == 0.0, 1, unions) - 10) / 10)\n    return np.mean(np.where(unions == 0, 1, ious))\n\ndef pixel_error(y_trues_in, y_preds_in):\n    y_true = (y_trues_in >= 0.5).squeeze()\n    y_pred = (y_preds_in >= 0.5).squeeze()\n    eq = (y_true == y_pred).sum()\n    ones = np.ones_like(y_true)\n    return 1 - eq / ones.sum()\n\ndef dice_batch(y_trues_in, y_preds_in):\n    y_true = (y_trues_in >= 0.5).squeeze()\n    y_pred = (y_preds_in >= 0.5).squeeze()\n    score = 0.0\n    for im1, im2 in zip(y_true, y_pred):\n        im_sum = im1.sum() + im2.sum()\n        if im_sum == 0:\n            score += 1.0\n            continue\n        intersection = np.logical_and(im1, im2)\n        score += (2. * intersection.sum() / im_sum)\n    return score / y_pred.shape[0]\n\ndef rand_error(y_trues_in, y_preds_in):\n    y_true = (y_trues_in >= 0.5).squeeze()\n    y_pred = (y_preds_in >= 0.5).squeeze()\n    rand_index = 0\n    for v1, v2 in zip(y_true, y_pred):\n        n = v1.shape[0] * v1.shape[1]\n        s1 = [n - v1.sum(), v1.sum()]\n        s2 = [n - v2.sum(), v2.sum()]\n        M = [[0,0], [0,0]]\n        M[0][0] = np.logical_and(np.logical_not(v1), np.logical_not(v2)).sum()\n        M[0][1] = np.logical_and(np.logical_not(v1), v2).sum()\n        M[1][0] = np.logical_and(v1, np.logical_not(v2)).sum()\n        M[1][1] = np.logical_and(v1, v2).sum()\n        a, b = 0, 0\n        for i in range(2):\n            for j in range(2):\n                c = M[i][j]\n                a += (c * (c - 1))\n                b += (c * (n - s1[i] - s2[j] + c))\n        cur = (a + b) / (n * (n - 1))\n        rand_index += cur\n    rand_index /= y_true.shape[0]\n    return 1 - rand_index\n\niou_score = iou_batch(Y_test, Y_pred)\ndice_score = dice_batch(Y_test, Y_pred)\npixel_err = pixel_error(Y_test, Y_pred)\nrand_err = rand_error(Y_test, Y_pred)\nprint('IOU   score : %.4f' % iou_score)\nprint('DICE  score : %.4f' % dice_score)\nprint('Pixel error : %.4f' % pixel_err)\nprint('Rand  error : %.4f' % rand_err)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}